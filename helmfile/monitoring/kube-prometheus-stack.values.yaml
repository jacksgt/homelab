# https://github.com/prometheus-community/helm-charts/blob/kube-prometheus-stack-79.1.0/charts/kube-prometheus-stack/values.yaml

cleanPrometheusOperatorObjectNames: true

defaultRules:
  rules: {}
  disabled: {}

alertmanager:
  enabled: false

# https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
grafana:
  enabled: true
  # Note: adminUser and adminPassword are set in kube-prometheus-stack.secret.yaml
  initChownData:
    enabled: false
  rbac:
    namespaced: true
  serviceMonitor:
    enabled: false
  deploymentStrategy:
    type: Recreate
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 512Mi
  grafana.ini:
    analytics:
      enabled: false
      check_for_updates: false
    server:
      root_url: https://monitoring.cubieserver.de/grafana
      serve_from_sub_path: true
      enable_gzip: true
    database:
      type: sqlite3
      wal: true

  # Note: dashboard configmaps and sidecar config containers are only enabled for initial import
  defaultDashboardsEnabled: false
  sidecar:
    dashboards:
      enabled: false
      searchNamespace: monitoring
    datasources:
      enabled: false
      searchNamespace: monitoring
    alerts:
      enabled: false
      searchNamespace: monitoring

  networkPolicy:
    enabled: true
    ingress: true
    allowExternal: false
    explicitNamespacesSelector:
      matchLabels:
        kubernetes.io/metadata.name: traefik
  ingress:
    enabled: true
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-production
      traefik.ingress.kubernetes.io/router.entrypoints: websecure
    hosts:
      - monitoring.cubieserver.de
    path: "/grafana"
    tls:
      - secretName: monitoring-ingress-cert
        hosts:
          - monitoring.cubieserver.de
  persistence:
    enabled: true
    storageClassName: "internal-btrfs"
    accessModes:
      - ReadWriteOnce
    size: 1Gi
    finalizers:
      - kubernetes.io/pvc-protection

kubernetesServiceMonitors:
  enabled: true

kubeApiServer:
  # scrape data from Kube API server
  # disabled for now -- too many time-series
  enabled: false

kubelet:
  # scape data from each node's kubelet
  enabled: true
  serviceMonitor:
    probes: false
    cAdvisor: true
    metricRelabelings:
      - sourceLabels: [__name__]
        regex: "^(apiserver|authentication|kubeproxy|go|rest|workqueue)_(.+)"
        action: "drop"
      # high-cardinality metrics (buckets)
      - sourceLabels: [__name__]
        regex: "^(kubelet_runtime_operations_duration_seconds|storage_operation_duration_seconds)_(.+)"
        action: "drop"

kubeEtcd:
  # k3s uses SQLite as datastore instead of etcd
  enabled: false

kubeControllerManager:
  # doesn't work on k3s because scheduler is bundled into the main server
  enabled: false

kubeScheduler:
  # doesn't work on k3s because scheduler is bundled into the main server
  enabled: false

coreDns:
  # not sure how useful it is, disabled for now
  enabled: false

kubeDns:
  # using coreDns instead
  enabled: false

kubeProxy:
  enabled: false

kubeStateMetrics:
  enabled: true

kube-state-metrics:
  fullnameOverride: "kube-state-metrics"
  metricDenylist:
  - '(.+)_created$'
  - '(.+)_annotations$'
  - '^kube_pod_status_qos_class$'
  - '^kube_pod_tolerations$'

  # https://github.com/prometheus-community/helm-charts/blob/95c450b72c24fdc7724516d9d1302d4aea27932e/charts/kube-state-metrics/values.yaml#L299
  collectors:
  # - certificatesigningrequests
  # - configmaps
  - cronjobs
  - daemonsets
  - deployments
  # - endpoints
  # - horizontalpodautoscalers
  - ingresses
  - jobs
  # - leases
  # - limitranges
  # - mutatingwebhookconfigurations
  - namespaces
  - networkpolicies
  - nodes
  - persistentvolumeclaims
  - persistentvolumes
  # - poddisruptionbudgets
  - pods
  # - replicasets
  # - replicationcontrollers
  # - resourcequotas
  # - secrets
  # - services
  - statefulsets
  # - storageclasses
  # - validatingwebhookconfigurations
  # - volumeattachments

nodeExporter:
  enabled: true

# https://github.com/prometheus-community/helm-charts/blob/main/charts/prometheus-node-exporter/values.yaml
prometheus-node-exporter:
  fullnameOverride: "node-exporter"
  # https://github.com/prometheus/node_exporter#collectors
  extraArgs:
    - "--collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/kubelet/.+|run/.*)($|/)"
    - "--collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|ramfs|rpc_pipefs|shmfs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$"
    - "--collector.diskstats.ignored-devices=^(ram|loop|fd|(h|s|v)d[a-z]|nvme\\d+n\\d+p)\\d+$"
    - "--collector.arp.device-exclude=.+"
    - "--collector.qdisk.device-exclude=.+"
    - "--collector.netdev.device-exclude=^(veth).+"

  prometheus:
    monitor:
      relabelings:
      # add the Kubernetes "node" as a label as well, otherwise we get just the instance (e.g. "1.2.3.4:10800")
      - sourceLabels: [__meta_kubernetes_pod_node_name]
        action: replace
        targetLabel: node
      metricRelabelings:
      - sourceLabels: [__name__]
        separator: ;
        regex: "^node_(ipvs|netstat|nf|schedstat|sockstat|timex|udp|softnet)_.+"
        replacement: $1
        action: drop
      - sourceLabels: [job, device]
        separator: ;
        regex: "^node-exporter;veth.+"
        replacement: $1
        action: drop
      - sourceLabels: [__name__]
        separator: ;
        regex: "^go_.+"
        replacement: $1
        action: drop

prometheusOperator:
  enabled: true

prometheus:
  enabled: true

  ingress:
    enabled: false

  prometheusSpec:
    # https://github.com/prometheus/prometheus/releases
    image:
      registry: quay.io
      repository: prometheus/prometheus
      tag: "v3.7.3"
      pullPolicy: IfNotPresent

    nodeSelector:
      cubieserver.de/local-storage: "true"
    retention: 90d

    resources:
      requests:
        cpu: 100m
        memory: 250Mi
      limits:
        cpu: 500m
        memory: 500Mi
    # https://stackoverflow.com/a/65648944
    podMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false
    storageSpec:
      volumeClaimTemplate:
        spec:
          # use XFS filesystem for Prometheus database (instead of btrfs)
          storageClassName: local-path-xfs
          resources:
            requests:
              storage: 1 # local-path ignores storage requests

thanosRuler:
  enabled: false
